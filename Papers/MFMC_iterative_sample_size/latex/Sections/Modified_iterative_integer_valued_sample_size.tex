% ====================================================
\section{Modified iterative sample size estimation for MFMC}\label{sec:Modified_IntegerValued_Sample_Size}
% ====================================================
A direct flooring of real-valued MFMC allocations can lead to pathological cases where high-fidelity models receive zero samples due to their substantial computational costs, resulting in degenerate estimators that violate the fundamental variance reduction principles of multifidelity methods. To address this critical limitation, we extend the modified rounding procedure introduced in~\cite{GrGuJuWa:2023} within our iterative framework, ensuring robust estimator construction while maintaining theoretical guarantees.

\subsection{Modified Allocation Framework}

The core modification enforces a minimum of one sample per fidelity level while preserving exact budget adherence. This is achieved through an iterative redistribution mechanism: whenever a computed sample size falls below unity, it is set to one, and the residual budget is reallocated among remaining models according to the continuous optimality principle. Formally, this corresponds to the integer-constrained optimization problem:
%
\begin{equation}\label{eq:Optimization_pb_integer}
    \begin{array}{ll}
    \min  &\sum_{k=1}^K\frac{\Delta_k}{N_k},\\
       \text{subject to} &\displaystyle\sum\limits_{k=1}^K C_kN_k\le p,\\[2pt]
       &\displaystyle N_1\ge 1,\quad \displaystyle N_{k-1}-N_k\le 0, \;\; k=2\ldots,K,\\
       &N_1,\ldots, N_K\in \mathbb{N}.
       % &\alpha_2,\ldots,\alpha_K\in \mathbb{R}.
    \end{array}
\end{equation}
%
Let $i$ denote the first index where the continuous solution yields $N_k^* \geq 1$ for all $k \geq i$. The modified allocation takes the form
%
\begin{equation}
    \label{eq:Modified_sample_size_floor_real_valued}
    N_1^* =\ldots=N_{i-1}^*= 1, \qquad N_k^* = \sqrt{\dfrac{\Delta_k}{C_k}}
        \dfrac{p - \sum_{j=1}^{i-1} C_j}
        {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}},\quad  i \le k \le K,
\end{equation}
%
followed by taking the floor of $N_k^*$.
As established in~\cite{GrGuJuWa:2023}, this formulation yields the unique global minimizer under integer constraints when using optimal weights in \eqref{eq:MFMC_weights}. The corresponding budget utilization and variance of the real-valued solution are given by
%
\begin{equation}\label{eq:Modified_f_real_valued}
    \sum_{k=1}^K C_k N_k^* = p, 
    \qquad 
    f(N_k^*) = \sum_{k=1}^K \frac{\Delta_k}{N_k^*}
    = \sum_{k=1}^{i-1} \Delta_k 
    + \frac{\left(\sum_{k=i}^K \sqrt{C_k \Delta_k}\right)^2}
    {p - \sum_{k=1}^{i-1} C_k}.
\end{equation}
%


\subsection{Iterative Extension of Modified Allocation}

We now extend our iterative framework to accommodate this modified allocation strategy. Unlike the original approach in~\cite{GrGuJuWa:2023} which uses direct computation of remaining allocations, our method applies the iterative principle uniformly across all fidelity levels
\begin{equation}
    \label{eq:Modified_sample_size_iterative_real_valued}
    H_1^* = \ldots = H_{i-1}^* =1, \qquad H_k^*=\sqrt{\frac{\Delta_k}{C_k}}\frac{p-\sum_{j=1}^{k-1}C_j  H_j^* }{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\end{equation}

The following theorem establishes the equivalence between this iterative formulation and the modified allocation, ensuring consistency with the original optimization objective.





% %
% \begin{equation}
%     \label{eq:Modified_sample_size_floor_real_valued}
%     N_k^* =
%     \begin{cases}
%         1, & 1 \le k < i, \\[4pt]
%         \sqrt{\dfrac{\Delta_k}{C_k}}
%         \dfrac{p - \sum_{j=1}^{i-1} C_j}
%         {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}}, & i \le k \le K,
%     \end{cases}
% \end{equation}
% %

\begin{theorem}[Equivalence of Iterative and Modified MFMC Allocations]
\label{thm:MFMC_modified_Iterative_RealValued_Sample_Size}
Let $\{H_k^*\}_{k=1}^K$ be defined by the iterative scheme \eqref{eq:Modified_sample_size_iterative_real_valued} and $\{N_k^*\}_{k=1}^K$ by the modified allocation \eqref{eq:Modified_sample_size_floor_real_valued}. Under the budget admissibility condition \eqref{eq:p_bound} and standard variance assumptions on $\Delta_k$, these allocations are identical:
\[
H_k^* = N_k^*, \quad \forall k = 1,\ldots,K.
\]
Consequently, both allocations achieve identical budget utilization and variance performance:
\[
\sum_{k=1}^K C_k H_k^* = p, 
\quad \text{and} \quad
f(H_k^*) = \sum_{k=1}^{i-1} \Delta_k + \frac{\left(\sum_{k=i}^K \sqrt{C_k \Delta_k}\right)^2}{p - \sum_{k=1}^{i-1} C_k}.
\]
\end{theorem}



\begin{proof}
Define the cumulative cost and the remaining budget by
%
\[
T_k = \sum_{j=1}^k C_j H_j^*, 
\qquad 
R_k = p - T_k.
\]
%
For the first $i-1$ fidelities, we have $H_j^* = 1$, hence
%
\[
T_k = \sum_{j=1}^k C_j, \qquad R_k = p - \sum_{j=1}^k C_j, \qquad 1 \le k < i-1.
\]
%
For $i \le k \le K$, substituting the iterative definition \eqref{eq:Modified_sample_size_iterative_real_valued} gives
%
\[
H_k^* 
= \sqrt{\frac{\Delta_k}{C_k}}
  \frac{R_{k-1}}{\sum_{j=k}^{K} \sqrt{C_j \Delta_j}},
\]
%
Combining these relations yields the recurrence
%
\[
R_k = R_{k-1} - C_k H_k^*
=
\frac{\sum_{j=k+1}^{K} \sqrt{C_j \Delta_j}}
       {\sum_{j=k}^{K} \sqrt{C_j \Delta_j}} R_{k-1},
\qquad i \le k \le K.
\]
%
Iterating this expression from $R_{i-1} = p - \sum_{j=1}^{i-1} C_j$ gives
%
\[
R_k 
= 
\frac{\sum_{j=k+1}^{K} \sqrt{C_j \Delta_j}}
       {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}}
  \left( p - \sum_{j=1}^{i-1} C_j \right),
\qquad i \le k \le K.
\]
%
Substituting this result back into the definition of $H_k^*$ yields
%
\[
H_k^*
= \sqrt{\frac{\Delta_k}{C_k}}
  \frac{R_{k-1}}{\sum_{j=k}^{K} \sqrt{C_j \Delta_j}}
= \sqrt{\frac{\Delta_k}{C_k}}
  \frac{p - \sum_{j=1}^{i-1} C_j}
       {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}},
\qquad i \le k \le K.
\]
%
Thus $H_k^* = N_k^*$ for all $k$, establishing the equivalence. 
% Substituting $H_k^*$ into $f(H_k^*) = \sum_{k=1}^K \Delta_k / H_k^*$ 
% gives the desired variance expression, completing the proof.
\end{proof}


\subsection{Integer-Valued Allocation}
Extending to integer-valued allocations, we define the proxy sequence $\{M_k^*\}$ through iterative flooring and budget updates
%
\begin{equation}
    \label{eq:Modified_sample_size_iterative_integer_proxy}
    M_1^*=\cdots=M_{i-1}^*=1, \qquad 
    M_k^*=\sqrt{\frac{\Delta_k}{C_k}}
    \frac{p-\sum_{j=1}^{k-1} C_j\left\lfloor M_j^*\right\rfloor}
         {\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\end{equation}
%

The following theorems establish that this approach achieves superior resource utilization and variance performance compared to direct flooring of the modified allocation.


\begin{theorem}[Cost bound for modified iterative integer-valued sample allocation]
\label{thm:MFMC_modified_integer_cost}
Let $\lfloor N_k^* \rfloor$ denote the integer allocation from direct flooring of \eqref{eq:Modified_sample_size_floor_real_valued}, and $\lfloor M_k^* \rfloor$ the iterative integer allocation. Under budget admissibility \eqref{eq:p_bound}, the integer-valued costs satisfy
\[
\sum_{k=1}^K C_k \left\lfloor N_k^* \right\rfloor\;\le\; \sum_{k=1}^K C_k\left\lfloor M_k^* \right\rfloor \;\le\; p.
\]
\end{theorem}




\begin{proof}
Define the remaining budget after assigning the first $k$ integer proxy allocations by 
\[
R_k = p-\sum_{j=1}^k C_j \left\lfloor M_j^* \right\rfloor, \quad \text{for}\quad i\le k\le K.
\]
with the convention $R_0=p$. By construction of the proxy, for $k\ge i$ we have
%
\begin{equation}\label{eq:M_def_proof}
    M_k^*=\sqrt{\frac{\Delta_k}{C_k}}\frac{R_{k-1}}{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}.
\end{equation}
%
We first show $\sum_{k=1}^K C_k\lfloor M_k^*\rfloor \le p$, equivalently $R_K\ge 0$.
Because $\lfloor M_k^*\rfloor \le M_k^*$ and using \eqref{eq:M_def_proof}, for $k\ge i$,
\[
C_k \left\lfloor M_k^* \right\rfloor\le \sqrt{C_k\Delta_k}\frac{R_{k-1}}{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\]
Hence
%
\begin{equation*}
    R_k = R_{k-1}-C_k  \left\lfloor M_k^* \right\rfloor\ge R_{k-1}\left(1-\frac{\sqrt{C_k\Delta_k}}{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}\right) = R_{k-1}\frac{\sum_{j=k+1}^{K}\sqrt{C_j\Delta_j}}{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\end{equation*}
%
Iterating this inequality starting from
%
\[
R_{i-1} \;=\; p - \sum_{j=1}^{i-1} C_j \left\lfloor M_j^*\right\rfloor
         \;=\; p - \sum_{j=1}^{i-1} C_j
\]
%
(since $\lfloor M_j^*\rfloor =1$ for $j<i$ by construction) yields,
%
\begin{equation}\label{eq:modified_proof_recursion}
R_{k}\ge \left(p-\sum_{j=1}^{i-1}C_j\right)\frac{\sum_{j=k+1}^K \sqrt{C_j\Delta_j}}{\sum_{j=i}^K \sqrt{C_j\Delta_j}},\quad i\le k\le K.
\end{equation}
%
In particular, for $k=K$ we obtain $R_K\ge 0$, which is equivalent to
%
\begin{equation*}\label{eq:modified_total_cost}
    \sum_{k-1}^K C_k\left\lfloor M_k^* \right\rfloor=p-R_K\le p,
\end{equation*}
proving the upper bound.

We now show
$\sum_{k=1}^K C_k\lfloor N_k^*\rfloor \le \sum_{k=1}^K C_k\lfloor M_k^*\rfloor$.
Substituting \eqref{eq:modified_proof_recursion} into \eqref{eq:M_def_proof} gives
%
\begin{equation}\label{eq:Modified_nondecreasing_sample_size_proof}
    M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_{k-1}}{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}\ge \sqrt{\frac{\Delta_k}{C_k}}\frac{p-\sum_{j=1}^{i-1}C_j}{\sum_{j=i}^K \sqrt{C_j\Delta_j}}=N_k^*, \quad i\le k\le K.
\end{equation}
%
For $k<i$ we already have $M_k^*=N_k^*=1$. Since the floor function is monotone non-decreasing, it follows that $\lfloor N_k^* \rfloor\le \lfloor M_k^* \rfloor$, and this prove the lower bound.
\end{proof}


\begin{theorem}[Variance Bound for Modified Integer-Valued Allocation]
\label{thm:MFMC_IntegerValued_Variance_Bound}
Let $\lfloor M_k^* \rfloor$ and $\lfloor N_k^* \rfloor$ be defined as above. Under the same assumptions:
\[
\frac{1}{p}\left(\sum_{k=1}^K\sqrt{C_k\Delta_k}\right)^2
\le \sum_{k=1}^K \frac{\Delta_k}{\left\lfloor M_k^* \right\rfloor}
\le \sum_{k=1}^K \frac{\Delta_k}{\left\lfloor N_k^* \right\rfloor}.
\]
\end{theorem}
\begin{proof}
The left inequality reflects the optimal continuous variance as a lower bound. The right inequality follows from $\lfloor M_k^* \rfloor \geq \lfloor N_k^* \rfloor$ for all $k$ (established inductively from the cost theorem), combined with the monotonicity of $x \mapsto \Delta_k/x$ for $x > 0$.
\end{proof}

% \begin{proof}
% Similar proof as that in Theorem \ref{thm:MFMC_New_IntegerValued_Variance}. 
% Since $\lfloor N_k^* \rfloor \le \lfloor M_k^* \rfloor$ for all $k$ in \eqref{eq:Modified_nondecreasing_sample_size_proof}, we immediately have the upper bound. To establish the lower bound, we apply the Cauchyâ€“Schwarz inequality,
% %
% \[
% \left(\sum_{k=1}^K \sqrt{C_k \Delta_k}\right)^2
% \le 
% \left(\sum_{k=1}^K C_k \left\lfloor M_k^* \right\rfloor \right)
% \left(\sum_{k=1}^K \frac{\Delta_k}{\left\lfloor M_k^* \right\rfloor}\right).
% \]
% %
% By the cost constraint for the iterative allocation 
% (cf.~\eqref{eq:modified_total_cost}), we have 
% \(\sum_{k=1}^K C_k \lfloor M_k^* \rfloor \le p\). 
% Substituting this bound gives the lower bound. This completes the proof.
% \end{proof}




% \begin{align*}
%     \frac{\partial L}{\partial \alpha_k}&=\left(\frac{1}{N_{k-1}} - \frac{1}{N_{k}}\right)\left(2\alpha_{k}\sigma_{k}^2 - 2\rho_{1,k}\sigma_1\sigma_{k}\right)=0.
% \end{align*}
% By \cite{PeWiGu:2016}, and the corresponding Lagrangian reads
% %
% \begin{equation}\label{eq: Lagrangian_for_modified_sample_size}
%     L = \mathbb{V}\left[A^{\text{MF}}\right]+\lambda_0\left(\sum_{k=i}^KC_kN_k-\left(p-\sum_{k=1}^{i-1}C_k\right)\right)-\lambda_k N_k+\sum_{k=i+1}^K \lambda_k(N_k-N_{k-1})
% \end{equation}
% %


% $L$ has a unique global minimum when $N_k$ is strictly increasing for $k>i$, therefore 
% \[
% \alpha_{k}^* = \frac{\rho_{1,k}\sigma_1}{\sigma_{k}}.
% \]
% %
% \[
% \frac{\partial L}{\partial N_k} = - \frac{\sigma_1^2\Delta_{k}}{N_{k}^2} +\lambda_0 C_{k}-\lambda_{k}+\lambda_{k+1}=0,\qquad i\le k\le K.
% \]

This iterative extension establishes a unified computational framework that preserves the robustness guarantees of modified allocation strategies while systematically leveraging the computational advantages and theoretical foundations of dynamic programming. By maintaining mathematical consistency with the original MFMC optimality principles, the approach ensures that fundamental variance-cost balancing properties are retained throughout the allocation process, even under practical integer constraints. The sequential decomposition transforms complex integer-constrained optimization into a series of tractable subproblems, enabling efficient implementation with linear computational complexity in the number of fidelity levels. Simultaneously, the minimum sample enforcement mechanism prevents pathological allocations that could compromise estimator stability, while iterative budget redistribution ensures full utilization of computational resources. The framework's unified structure further permits seamless integration of various constraint handling strategies and domain-specific requirements, offering both theoretical rigor and practical utility for robust multifidelity estimation under realistic computational constraints.


% \begin{algorithm}[!ht]
% \caption{Iterative Integer-Valued Sample Size Allocation for Multi-Fidelity Monte Carlo}
% \label{algo:Iterative_MFMC_Algo}
% \DontPrintSemicolon

% \KwIn{Correlation coefficients $\rho_{1,k}$, standard deviations $\sigma_k$, computational costs $C_k$, total budget $p$.}
% \KwOut{Integer-valued sample sizes $\lfloor M_k^* \rfloor$ for $k=1,\dots,K$.}
% \hrule\vspace{1ex}

% \If{$p < \sum_{j=1}^K C_j$}{
%     \textbf{return} ``Insufficient budget: requires at least $\sum_{j=1}^K C_j$''.
% }

% Compute variance terms: $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$.

% % Compute normalization constant: $S = \sum_{i=1}^K \sqrt{C_i \Delta_i}$\;

% Initialize with first fidelity level:
% \[
% M_1^* = \sqrt{\frac{\Delta_1}{C_1}} \frac{p}{ \sum_{j=1}^K \sqrt{C_j \Delta_j}}.
% \]

% \For{$k = 2$ \KwTo $K$}{
%     Update residual budget: $R_k = p - \sum_{j=1}^{k-1} C_j \lfloor M_j^* \rfloor$.\;
%     Compute current allocation:
%     \[
%     M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_k}{\sum_{j=k}^K \sqrt{C_j \Delta_j}}.
%     \]
%     \If{$\lfloor M_k^* \rfloor < 1$}{
%         Enforce minimum sample: $\lfloor M_k^* \rfloor = 1$.
%     }
% }
% \textbf{return} $\lfloor M_1^* \rfloor, \dots, \lfloor M_K^* \rfloor$.
% \end{algorithm}


\begin{algorithm}[!ht]
\caption{Iterative Integer-Valued Sample Size Allocation for Multi-Fidelity Monte Carlo}
\label{algo:Iterative_MFMC_Algo}
\DontPrintSemicolon

\KwIn{Correlation coefficients $\rho_{1,k}$, standard deviations $\sigma_k$, computational costs $C_k$, total budget $p$.}
\KwOut{Integer-valued sample sizes $\lfloor M_k^* \rfloor$ for $k=1,\dots,K$.}
\hrule\vspace{1ex}

\If{$p < \sum_{j=1}^K C_j$}{
    \textbf{return} ``Insufficient budget: requires at least $\sum_{j=1}^K C_j$''.
}

Compute variance terms: $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$.

% Compute normalization constant: $S = \sum_{i=1}^K \sqrt{C_i \Delta_i}$\;

Initialize with first fidelity level:
\[
M_1^* = \sqrt{\frac{\Delta_1}{C_1}} \frac{p}{ \sum_{j=1}^K \sqrt{C_j \Delta_j}}.
\]

\For{$k = 2$ \KwTo $K$}{
    Update residual budget: $R_k = p - \sum_{j=1}^{k-1} C_j \lfloor M_j^* \rfloor$.\;
    Compute current allocation:
    \[
    M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_k}{\sum_{j=k}^K \sqrt{C_j \Delta_j}}.
    \]
    \If{$\lfloor M_k^* \rfloor < 1$}{
        Enforce minimum sample: $\lfloor M_k^* \rfloor = 1$.
    }


\If{$\lfloor M_{k-1}^* \rfloor=\lfloor M_k^* \rfloor$}{
    Let $\boldsymbol{\rho} = [\rho_{1,1}, \ldots, \rho_{1,K}], \boldsymbol{C} = [C_{1}, \ldots, C_{K}]$
    
    
    Check condition (2):
    
    
    $\widetilde\Delta_{k-1}=\rho_{1,k-1}^2 - \rho_{1,k+1}^2, \widetilde\Delta_k = \rho_{1,k+1}^2-\rho_{1,k+2}^2$

    
    calculate condition (2) $\frac{\widetilde\Delta_{k-1}}{C_{k-1}}<\frac{\widetilde\Delta_{k}}{C_{k+1}}$
    
    \If{condition (2) holds without model $k$}{ 
    $\lfloor M_k^* \rfloor=0$.
    
    delete model $k$, $\boldsymbol{\rho}(k)=[], \boldsymbol{C}(k)=[]$
    
    update $\boldsymbol{\rho}$ and $\boldsymbol{C}$,
    $K=K-1$,
    
    $k=2$, start from beginning of the for loop with the update $\boldsymbol{\rho}$ and $\boldsymbol{C}$.
    }
    
    \Else{otherwise keep model $k$.}
    
}
}
\textbf{return} $\lfloor M_1^* \rfloor, \dots, \lfloor M_K^* \rfloor$.
\end{algorithm}
