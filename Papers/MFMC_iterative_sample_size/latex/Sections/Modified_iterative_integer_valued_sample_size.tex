% ====================================================
\section{Modified iterative sample size estimation for MFMC}\label{sec:Modified_IntegerValued_Sample_Size}
% ====================================================
When the computational budget $p$ is small, direct flooring of the real-valued MFMC sample allocations may lead to pathological cases in which high-fidelity models receive zero samples. Such degenerate allocations destroy the variance reduction property of multifidelity estimators and undermine the optimal variance--cost tradeoff. To overcome this limitation, we extend the modified rounding procedure proposed in~\cite{GrGuJuWa:2023} and embed it within our iterative allocation framework. As established in Section~\ref{sec:MFMC}, identical sample sizes across successive fidelity levels do not contribute to variance reduction but still incur additional computational cost. Motivated by this observation, we further refine the allocation procedure by eliminating models with equal integer-valued sample sizes during the iteration. The resulting subset of selected models satisfies a strictly increasing sequence of integer sample sizes across fidelities, thereby ensuring efficient utilization of the available budget and preservation of the hierarchical variance decay structure inherent to the MFMC method.




\subsection{Modified Allocation Framework}

The core modification enforces a minimum of one sample per fidelity level while preserving exact budget adherence. This is achieved through an iterative redistribution mechanism: whenever a computed sample size falls below unity, it is set to one, and the residual budget is reallocated among remaining models according to the continuous optimality principle. Formally, this corresponds to the integer-constrained optimization problem:
%
\begin{equation}\label{eq:Optimization_pb_integer}
    \begin{array}{ll}
    \min  &\sum_{k=1}^K\frac{\Delta_k}{N_k},\\
       \text{subject to} &\displaystyle\sum\limits_{k=1}^K C_kN_k\le p,\\[2pt]
       &\displaystyle N_1\ge 1,\quad \displaystyle N_{k-1}-N_k\le 0, \;\; k=2\ldots,K,\\
       &N_1,\ldots, N_K\in \mathbb{N}.
       % &\alpha_2,\ldots,\alpha_K\in \mathbb{R}.
    \end{array}
\end{equation}
%
Let $i$ denote the first index where the continuous solution yields $N_k^* \geq 1$ for all $k \geq i$. The modified allocation takes the form
%
\begin{equation}
    \label{eq:Modified_sample_size_floor_real_valued}
    N_1^* =\ldots=N_{i-1}^*= 1, \qquad N_k^* = \sqrt{\dfrac{\Delta_k}{C_k}}
        \dfrac{p - \sum_{j=1}^{i-1} C_j}
        {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}},\quad  i \le k \le K,
\end{equation}
%
followed by taking the floor of $N_k^*$.
As established in~\cite{GrGuJuWa:2023}, this formulation yields the unique global minimizer under integer constraints when using optimal weights in \eqref{eq:MFMC_weights}. The corresponding budget utilization and variance of the real-valued solution are given by
%
\begin{equation}\label{eq:Modified_f_real_valued}
    \sum_{k=1}^K C_k N_k^* = p, 
    \qquad 
    f(N_k^*) = \sum_{k=1}^K \frac{\Delta_k}{N_k^*}
    = \sum_{k=1}^{i-1} \Delta_k 
    + \frac{\left(\sum_{k=i}^K \sqrt{C_k \Delta_k}\right)^2}
    {p - \sum_{k=1}^{i-1} C_k}.
\end{equation}
%


\subsection{Iterative Extension of Modified Allocation}

We now extend our iterative framework to accommodate this modified allocation strategy. Unlike the original approach in~\cite{GrGuJuWa:2023} which uses direct computation of remaining allocations, our method applies the iterative principle uniformly across all fidelity levels
\begin{equation}
    \label{eq:Modified_sample_size_iterative_real_valued}
    H_1^* = \ldots = H_{i-1}^* =1, \qquad H_k^*=\sqrt{\frac{\Delta_k}{C_k}}\frac{p-\sum_{j=1}^{k-1}C_j  H_j^* }{\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\end{equation}

The following theorem establishes the equivalence between this iterative formulation and the modified allocation, ensuring consistency with the original optimization objective.





% %
% \begin{equation}
%     \label{eq:Modified_sample_size_floor_real_valued}
%     N_k^* =
%     \begin{cases}
%         1, & 1 \le k < i, \\[4pt]
%         \sqrt{\dfrac{\Delta_k}{C_k}}
%         \dfrac{p - \sum_{j=1}^{i-1} C_j}
%         {\sum_{j=i}^{K} \sqrt{C_j \Delta_j}}, & i \le k \le K,
%     \end{cases}
% \end{equation}
% %

\begin{theorem}[Equivalence of Iterative and Modified MFMC Allocations]
\label{thm:MFMC_modified_Iterative_RealValued_Sample_Size}
Let $\{H_k^*\}_{k=1}^K$ be defined by the iterative scheme \eqref{eq:Modified_sample_size_iterative_real_valued} and $\{N_k^*\}_{k=1}^K$ by the modified allocation \eqref{eq:Modified_sample_size_floor_real_valued}. Under the budget admissibility condition \eqref{eq:p_bound} and standard variance assumptions on $\Delta_k$, these allocations are identical:
\[
H_k^* = N_k^*, \quad \forall k = 1,\ldots,K.
\]
Consequently, both allocations achieve identical budget utilization and variance performance:
\[
\sum_{k=1}^K C_k H_k^* = p, 
\quad \text{and} \quad
f(H_k^*) = \sum_{k=1}^{i-1} \Delta_k + \frac{\left(\sum_{k=i}^K \sqrt{C_k \Delta_k}\right)^2}{p - \sum_{k=1}^{i-1} C_k}.
\]
\end{theorem}



\begin{proof}
Define the cumulative cost and the remaining budget as
%
\[
T_k = \sum_{j=1}^k C_j H_j^*,\quad k=1\ldots, K,
\qquad 
R_1=p,
\qquad 
R_k = p - T_{k-1}, \quad k=2, \ldots, K.
\]
%
For $k=i,\ldots,K$, the budget residual satisfies
\[
R_k = R_{k-1} - C_{k-1} H_{k-1}^* = \frac{S_k}{S_{k-1}} R_{k-1}.
\]
For the first $i-1$ fidelities, $H_k^* = 1$, hence
\[
R_i = p - \sum_{j=1}^{i-1} C_j,
\]
and iterating the recurrence gives
\[
R_k = \frac{S_k}{S_i} R_i 
      = \frac{S_k}{S_i} \left(p - \sum_{j=1}^{i-1} C_j\right), 
\quad k=i,\ldots,K.
\]
Substituting into \eqref{eq:Modified_sample_size_iterative_real_valued} yields
\[
H_k^* = \sqrt{\frac{\Delta_k}{C_k}} \frac{R_k}{S_k} 
       = \sqrt{\frac{\Delta_k}{C_k}} 
         \frac{p - \sum_{j=1}^{i-1} C_j}{\sum_{j=i}^{K} \sqrt{C_j \Delta_j}}, 
\quad k=i,\ldots,K.
\]
Thus $H_k^* = N_k^*$ for all $k$, establishing the equivalence.
\end{proof}



\subsection{Integer-valued Allocation}
Extending to integer-valued allocations, we define the proxy sequence $\{M_k^*\}$ through iterative flooring and budget updates
%
\begin{equation}
    \label{eq:Modified_sample_size_iterative_integer_proxy}
    M_1^*=\cdots=M_{i-1}^*=1, \qquad 
    M_k^*=\sqrt{\frac{\Delta_k}{C_k}}
    \frac{p-\sum_{j=1}^{k-1} C_j\left\lfloor M_j^*\right\rfloor}
         {\sum_{j=k}^{K}\sqrt{C_j\Delta_j}}, \quad i\le k\le K.
\end{equation}
%

The following theorems establish that this approach achieves superior resource utilization and variance performance compared to direct flooring of the modified allocation.


\begin{theorem}[Cost bound for modified iterative integer-valued sample allocation]
\label{thm:MFMC_modified_integer_cost}
Let $\lfloor N_k^* \rfloor$ denote the integer allocation from direct flooring of \eqref{eq:Modified_sample_size_floor_real_valued}, and $\lfloor M_k^* \rfloor$ the iterative integer allocation. Under budget admissibility \eqref{eq:p_bound}, the integer-valued costs satisfy
\[
\sum_{k=1}^K C_k \left\lfloor N_k^* \right\rfloor\;\le\; \sum_{k=1}^K C_k\left\lfloor M_k^* \right\rfloor \;\le\; p.
\]
\end{theorem}




\begin{proof}
Define the remaining budget after assigning the first $k$ integer proxy allocations by 
\[
R_k = p-\sum_{j=1}^{k-1} C_j \left\lfloor M_j^* \right\rfloor,
\qquad 
    k=i,\ldots, K
\]
with the convention $R_1=p$. By construction of the proxy, for $k\ge i$ we have
%
\begin{equation}\label{eq:M_def_proof}
    M_k^*=\sqrt{\frac{\Delta_k}{C_k}}\frac{R_{k}}{S_k},
    \qquad 
    k=i,\ldots, K
\end{equation}
%
We first show $\sum_{k=1}^K C_k\lfloor M_k^*\rfloor \le p$, equivalently $R_K\ge 0$.
Because $\lfloor M_k^*\rfloor \le M_k^*$ and using \eqref{eq:M_def_proof}, for $k\ge i$,
\[
C_k \left\lfloor M_k^* \right\rfloor\le \sqrt{C_k\Delta_k}\frac{R_{k}}{S_k}, \quad i\le k\le K.
\]
Hence
%
\begin{equation*}
    R_k = R_{k-1}-C_{k-1}  \left\lfloor M_{k-1}^* \right\rfloor\ge R_{k-1}\left(1-\frac{\sqrt{C_{k-1}\Delta_{k-1}}}{S_{k-1}}\right) = R_{k-1}\frac{S_{k}}{S_{k-1}}, \quad i\le k\le K.
\end{equation*}
%
Iterating this inequality starting from
%
\[
R_{i} \;=\; p - \sum_{j=1}^{i-1} C_j \left\lfloor M_j^*\right\rfloor
         \;=\; p - \sum_{j=1}^{i-1} C_j
\]
%
(since $\lfloor M_j^*\rfloor =1$ for $j<i$ by construction) yields,
%
\begin{equation}\label{eq:modified_proof_recursion}
R_{k}\ge \left(p-\sum_{j=1}^{i-1}C_j\right)\frac{S_{k}}{S_{i-1}},\quad i\le k\le K.
\end{equation}
%
Therefore,
%
\begin{equation*}\label{eq:modified_total_cost}
    \sum_{k=1}^K C_k\left\lfloor M_k^* \right\rfloor \le \sum_{k=1}^K\sqrt{C_k\Delta_k}\frac{R_{k}}{S_k}=\sum_{k=1}^{i-1}C_k+\sum_{k=i}^K\sqrt{C_k\Delta_k}\frac{R_{k}}{S_k} \le \sum_{k=1}^{i-1}C_k+\frac{R_{i}}{S_i}S_i=p,
\end{equation*}
proving the upper bound.

We now show
$\sum_{k=1}^K C_k\lfloor N_k^*\rfloor \le \sum_{k=1}^K C_k\lfloor M_k^*\rfloor$.
Substituting \eqref{eq:modified_proof_recursion} into \eqref{eq:M_def_proof} gives
%
\begin{equation}\label{eq:Modified_nondecreasing_sample_size_proof}
    M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_{k-1}}{S_k}\ge \sqrt{\frac{\Delta_k}{C_k}}\frac{p-\sum_{j=1}^{i-1}C_j}{S_i}=N_k^*, \quad i\le k\le K.
\end{equation}
%
For $k<i$ we already have $M_k^*=N_k^*=1$. Since the floor function is monotone non-decreasing, it follows that $\lfloor N_k^* \rfloor\le \lfloor M_k^* \rfloor$, and this prove the lower bound.
\end{proof}


\begin{theorem}[Variance Bound for Modified Integer-Valued Allocation]
\label{thm:MFMC_IntegerValued_Variance_Bound}
Let $\lfloor M_k^* \rfloor$ and $\lfloor N_k^* \rfloor$ be defined as above. Under the same assumptions:
\[
\frac{1}{p}\left(\sum_{k=1}^K\sqrt{C_k\Delta_k}\right)^2
\le \sum_{k=1}^K \frac{\Delta_k}{\left\lfloor M_k^* \right\rfloor}
\le \sum_{k=1}^K \frac{\Delta_k}{\left\lfloor N_k^* \right\rfloor}.
\]
\end{theorem}
\begin{proof}
The left inequality reflects the optimal continuous variance as a lower bound. The right inequality follows from $\lfloor M_k^* \rfloor \geq \lfloor N_k^* \rfloor$ for all $k$ (established inductively from the cost theorem), combined with the monotonicity of $x \mapsto \Delta_k/x$ for $x > 0$.
\end{proof}

% \begin{proof}
% Similar proof as that in Theorem \ref{thm:MFMC_New_IntegerValued_Variance}. 
% Since $\lfloor N_k^* \rfloor \le \lfloor M_k^* \rfloor$ for all $k$ in \eqref{eq:Modified_nondecreasing_sample_size_proof}, we immediately have the upper bound. To establish the lower bound, we apply the Cauchyâ€“Schwarz inequality,
% %
% \[
% \left(\sum_{k=1}^K \sqrt{C_k \Delta_k}\right)^2
% \le 
% \left(\sum_{k=1}^K C_k \left\lfloor M_k^* \right\rfloor \right)
% \left(\sum_{k=1}^K \frac{\Delta_k}{\left\lfloor M_k^* \right\rfloor}\right).
% \]
% %
% By the cost constraint for the iterative allocation 
% (cf.~\eqref{eq:modified_total_cost}), we have 
% \(\sum_{k=1}^K C_k \lfloor M_k^* \rfloor \le p\). 
% Substituting this bound gives the lower bound. This completes the proof.
% \end{proof}




% \begin{align*}
%     \frac{\partial L}{\partial \alpha_k}&=\left(\frac{1}{N_{k-1}} - \frac{1}{N_{k}}\right)\left(2\alpha_{k}\sigma_{k}^2 - 2\rho_{1,k}\sigma_1\sigma_{k}\right)=0.
% \end{align*}
% By \cite{PeWiGu:2016}, and the corresponding Lagrangian reads
% %
% \begin{equation}\label{eq: Lagrangian_for_modified_sample_size}
%     L = \mathbb{V}\left[A^{\text{MF}}\right]+\lambda_0\left(\sum_{k=i}^KC_kN_k-\left(p-\sum_{k=1}^{i-1}C_k\right)\right)-\lambda_k N_k+\sum_{k=i+1}^K \lambda_k(N_k-N_{k-1})
% \end{equation}
% %


% $L$ has a unique global minimum when $N_k$ is strictly increasing for $k>i$, therefore 
% \[
% \alpha_{k}^* = \frac{\rho_{1,k}\sigma_1}{\sigma_{k}}.
% \]
% %
% \[
% \frac{\partial L}{\partial N_k} = - \frac{\sigma_1^2\Delta_{k}}{N_{k}^2} +\lambda_0 C_{k}-\lambda_{k}+\lambda_{k+1}=0,\qquad i\le k\le K.
% \]


\subsection{Further Modification}
In \eqref{eq:Modified_sample_size_iterative_integer_proxy}, identical sample sizes across consecutive fidelity levels do not contribute to variance reduction yet still incur additional computational cost. To mitigate this inefficiency, we refine the iterative allocation by dynamically adjusting the set of active models. Specifically, instead of relying on a fixed subset of preselected models, we sequentially evaluate whether to eliminate models whose integer-valued sample sizes coincide with those of the preceding fidelity level. The elimination criterion is determined using the second condition of Theorem~\ref{thm:Sample_size_real}, applied to the parameters of the reduced model set after each elimination step. The first condition of the theorem is automatically satisfied, while the second condition ensures that the resulting subset exhibits strictly increasing sample sizes across fidelities.

This adaptive elimination strategy enables the model subset to adjust to the available computational budget~$p$, producing an allocation that maintains monotonicity and enhances variance decay relative to that obtained with a fixed model hierarchy. The complete procedure is summarized in Algorithm~\ref{algo:Iterative_MFMC_Algo}.




% \begin{algorithm}[!ht]
% \caption{Iterative Integer-Valued Sample Size Allocation for Multi-Fidelity Monte Carlo}
% \label{algo:Iterative_MFMC_Algo}
% \DontPrintSemicolon

% \KwIn{Correlation coefficients $\rho_{1,k}$, standard deviations $\sigma_k$, computational costs $C_k$, total budget $p$.}
% \KwOut{Integer-valued sample sizes $\lfloor M_k^* \rfloor$ for $k=1,\dots,K$.}
% \hrule\vspace{1ex}

% \If{$p < \sum_{j=1}^K C_j$}{
%     \textbf{return} ``Insufficient budget: requires at least $\sum_{j=1}^K C_j$''.
% }

% Compute variance terms: $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$.

% % Compute normalization constant: $S = \sum_{i=1}^K \sqrt{C_i \Delta_i}$\;

% Initialize with first fidelity level:
% \[
% M_1^* = \sqrt{\frac{\Delta_1}{C_1}} \frac{p}{ \sum_{j=1}^K \sqrt{C_j \Delta_j}}.
% \]

% \For{$k = 2$ \KwTo $K$}{
%     Update residual budget: $R_k = p - \sum_{j=1}^{k-1} C_j \lfloor M_j^* \rfloor$.\;
%     Compute current allocation:
%     \[
%     M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_k}{\sum_{j=k}^K \sqrt{C_j \Delta_j}}.
%     \]
%     \If{$\lfloor M_k^* \rfloor < 1$}{
%         Enforce minimum sample: $\lfloor M_k^* \rfloor = 1$.
%     }
% }
% \textbf{return} $\lfloor M_1^* \rfloor, \dots, \lfloor M_K^* \rfloor$.
% \end{algorithm}


\begin{algorithm}[!ht]
\caption{Iterative Integer-Valued Sample Size Allocation for Multi-Fidelity Monte Carlo}
\label{algo:Iterative_MFMC_Algo}
\DontPrintSemicolon

\KwIn{Correlation coefficients  $\{\rho_{1,k}\}_{k=1}^K$, computational costs $\{C_k\}_{k=1}^K$, total budget $p$.}
\KwOut{Integer-valued sample sizes $\{\lfloor M_k^* \rfloor\}_{k=1}^{K_r}$.}
\hrule\vspace{1ex}

\If{$p < \sum_{j=1}^K C_j$}{
    \textbf{return} ``Insufficient budget: requires at least $\sum_{j=1}^K C_j$''.
}

Let $\boldsymbol{\rho} = [\rho_{1,1}, \ldots, \rho_{1,K}], \boldsymbol{C} = [C_{1}, \ldots, C_{K}]$. 

Compute variance terms: $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$.

RestartFlag = true.\;

% Compute normalization constant: $S = \sum_{i=1}^K \sqrt{C_i \Delta_i}$\;
\While{RestartFlag}{

RestartFlag = false.\;
Initialize the real-valued optimal allocation:
\[
M_1^* = \sqrt{\frac{\Delta_1}{C_1}} \frac{p}{ \sum_{j=1}^K \sqrt{C_j \Delta_j}},
\qquad
\left\lfloor M_1^* \right\rfloor = \max \left(\left\lfloor M_1^* \right\rfloor, 1\right)
\]



\For{$k = 2$ \KwTo $K$}{
    Update residual budget: $R_k = p - \sum_{j=1}^{k-1} C_j \left\lfloor M_j^* \right\rfloor$.\;
    Compute the current allocation:
    \[
    M_k^* = \sqrt{\frac{\Delta_k}{C_k}}\frac{R_k}{\sum_{j=k}^K \sqrt{C_j \Delta_j}},
    \qquad
    \left\lfloor M_k^* \right\rfloor = \max \left(\left\lfloor M_k^* \right\rfloor, 1 \right).
    \]
    % \If{$\lfloor M_k^* \rfloor < 1$}{
    %     Enforce minimum sample: $\lfloor M_k^* \rfloor = 1$.
    % }


\If{$\left\lfloor M_{k-1}^* \right\rfloor=\left\lfloor M_k^* \right\rfloor$}{
    
    
    
    Compute updated variance: $\widetilde\Delta_{k-1}=\rho_{1,k-1}^2 - \rho_{1,k+1}^2, \widetilde\Delta_k = \rho_{1,k+1}^2-\rho_{1,k+2}^2$

    
    \If{condition $\frac{\widetilde\Delta_{k-1}}{C_{k-1}}<\frac{\widetilde\Delta_{k}}{C_{k+1}}$}{ 

    Discard model $k$: $\boldsymbol{\rho} \leftarrow \boldsymbol{\rho} \setminus \{\rho_{1,k}\}$, $\boldsymbol{C} \leftarrow \boldsymbol{C} \setminus \{C_k\}$,\;
    Update $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$,\;
    $K \leftarrow K - 1$.\;

    RestartFlag = true.\;

    Break.\;
    % \scr{Restart iteration with updated parameters and recompute $M_k^*$ from step 5.}
    }
    
    \Else{Retain model $k$.}
    
}
}
}
$K_r \leftarrow K$\;
\textbf{return} $\left\lfloor M_1^* \right\rfloor, \dots, \left\lfloor M_{K_r}^* \right\rfloor$.
\end{algorithm}

