% ========================================
\section{Introduction}\label{sec:intro}
% ========================================
The pursuit of controlled nuclear fusion as a clean and virtually limitless energy source has spurred extensive research into the physics of magnetic confinement in fusion reactors. At the core of this effort lies the Gradâ€“Shafranov free-boundary problem, which governs the equilibrium state of plasma in axially symmetric geometries, such as those found in Tokamaks. The governing equation encapsulates the intricate interplay between magnetic fields and plasma pressure, which determines critical confinement and stability properties essential for efficient plasma performance. However, the predictive accuracy of these models is significantly challenged by uncertainties in the parameters arising from measurement limitations, model assumptions, and operational variability. Addressing these uncertainties effectively requires advanced computational frameworks capable of robust statistical analysis, enabling accurate predictions of the plasma equilibrium response under diverse scenarios and ensuring reliable assessments of reactor designs and operations.

This study focuses on estimating the expectation of the solution operator associated with plasma equilibrium with uncertainties in the parameters. The Monte Carlo (MC) method, a classical and widely used approach in uncertainty quantification, relies on repeated executions of deterministic solvers to generate ensembles of realizations for stochastic inputs. Despite its versatility, its practicality is often limited by its slow asymptotic convergence rate of $1/\sqrt{N}$, which often requires a substantial number of sample realizations, $N$, to achieve reliable accuracy. For problems involving non-linear partial differential equations (PDEs), this slow convergence translates into a significant computational burden, as each realization typically demands a high-fidelity numerical approximation, such as those obtained via finite element method, which are computationally expensive due to their fine spatial resolution. Consequently, the cost of using the MC method can quickly escalate, particularly for high-dimensional problems or those requiring precise solutions. To alleviate this challenge, low-fidelity models have been proposed as computationally efficient alternatives to high-fidelity simulations.  These models aim to approximate the underlying system with reduced computational cost while maintaining an acceptable level of accuracy. For example, \cite{ElLiSa:2022} demonstrates how low-fidelity models constructed using stochastic collocation can effectively accelerate Monte Carlo sampling by exploiting simplified representations of the system. Similarly,
\cite{ElLiSa:2023} investigates hierarchical coarse spatial grids to develop low-fidelity surrogate models for multilevel Monte Carlo (MLMC) frameworks \cite{BaScZo:2011,Gi:2008}. Building on these ideas, studies such as \cite{ElLiSa:2025, Li:2024} combine stochastic collocation techniques with multilevel approaches, constructing low-fidelity models on coarse grids for MLMC sampling, further reducing computational expenses. While these methods achieve notable reductions in computational cost, they introduce the risk of compromising accuracy due to the inherent simplifications in the surrogate models. The trade-off between computational efficiency and solution accuracy is, therefore, a critical issue that warrants careful examination to ensure the reliability of results.


In this work, we delve into the multi-fidelity Monte Carlo (MFMC) method \cite{PeWiGu:2016, PeGuWi:2018}, which uses the control variate approach to exploit correlations between a computationally expensive high-fidelity model and a series of low-fidelity models. The MFMC method distinguishes itself from the MLMC approach by adopting a different strategy to construct its estimator. In MLMC, sample corrections are accumulated starting from the coarsest grid representation, using independent samples across successive spatial grid resolutions, and the sample size decreases with increasing grid fidelity to optimize computational effort. In contrast, the MFMC estimator follows an inverted paradigm: it initiates the accumulation of corrections with the most refined model representation and progressively incorporates corrections from lower-fidelity models. As the fidelity of the model decreases, the sample size increases, allowing less accurate but computationally inexpensive models to contribute to the overall estimate. Crucially, a distinguishing feature of the MFMC method is its reuse of samples within the same model hierarchy in the correction. This reuse avoids the computational redundancy of generating new samples at each fidelity level, effectively enhancing the overall efficiency of the sampling process. In addition to its computational efficiency, the MFMC method offers notable advantages over surrogate-based MLMC methods, such as those discussed in \cite{ElLiSa:2025, Li:2024}, which rely heavily on the characterization of interpolation errors. Such reliance can be a limiting factor, particularly in scenarios where interpolation errors decay slowly or require complicated error analysis. The MFMC approach circumvents this challenge by accommodating diverse surrogate models without taking into account the explicit treatment of interpolation errors, offering greater flexibility in its application. This adaptability extends the utility of MFMC to a broader range of modeling scenarios, making it particularly valuable in contexts where achieving a balance between computational efficiency and solution accuracy is critical. 

Nevertheless, the MFMC method is not without challenges. One notable limitation lies in its reliance on sufficiently large sample sizes to accurately estimate critical statistical parameters, such as variances and correlation coefficients, between high- and low-fidelity models. These estimates are obtained during the \textit{offline computations}, a preparatcory process involving tasks such as parameter estimation and the construction of surrogate models. Once the surrogates are built and parameters are generated in the offline phase, they will then be used in the \textit{online computations}, where the MFMC estimator is assembled and used to perform uncertainty quantification. However, achieving accurate parameter approximations in the offline phase can require substantial computational effort, which, in turn, may offset some of the efficiency gains in the online phase. Despite these challenges, the MFMC method remains an attractive approach due to its potential to accelerate the sampling process. The trade-offs between offline and online cost emphasize the importance of evaluating its applicability on a case-by-case basis to fully realize its potential benefits. In this study, we extend the analysis of the MFMC method \cite{PeWiGu:2016} by explicitly deriving the required sample size and computational cost as functions of the prescribed accuracy requirements. Our primary objective is to demonstrate that the MFMC method can achieve significant acceleration in the sampling process while maintaining statistical fidelity. As such, we show that MFMC provides a practical and robust framework for addressing the complex challenges of uncertainty quantification, particularly in the context of plasma equilibrium modeling.


 
The paper is organized as follows. In Section \ref{sec:Grad-Shafranov}, we introduce the Grad-Shafranov free boundary problem under uncertainty. Section \ref{sec:SC} provides an overview of the sparse grid stochastic collocation technique, which forms the basis to construct low-fidelity models used in the multi-fidelity Monte Carlo framework. Sections \ref{sec:MC} and \ref{sec:MFMC} discuss the Monte Carlo Finite Element method and its multi-fidelity variant. Finally, Section \ref{sec:Num-Exp} presents numerical experiments that access both efficiency and accuracy of these methods.



% Finally, the paper concludes with Section \ref{sec:Conclusion}, summarizing the key findings and contributions. 
% An appendix is included, containing technical mathematical details and proofs relevant to the problem and methods discussed.