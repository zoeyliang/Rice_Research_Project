% ========================================
\section{Introduction}\label{sec:intro}
% ========================================
The Monte Carlo (MC) method is a widely used approach for uncertainty quantification, relying on repeated evaluations of deterministic solvers to generate statistical estimates for stochastic inputs. Despite its generality, its convergence rate of $1/\sqrt{N}$, where $N$ is the number of samples, results in high computational costs, particularly for nonlinear partial differential equations (PDEs). These problems often require high-fidelity numerical approximations, such as finite element methods with fine spatial resolution, further increasing the computational burden. To mitigate these costs, the multilevel Monte Carlo (MLMC) \cite{Gi:2008,Gi:2015} method was introduced. By using a hierarchy of spatial discretizations, MLMC reduces the reliance on expensive high-fidelity evaluations. However, its implementation requires a structured discretization hierarchy and detailed fidelity error between the high and low fidelity models, limiting its flexibility in incorporating general surrogate models. The multifidelity Monte Carlo (MFMC) method \cite{PeGuWi:2018,PeWiGu:2016,PeWiGu:2018} offers an alternative approach, using the control variate technique to exploit correlations between a high-fidelity model and a set of lower-fidelity models. Unlike MLMC, MFMC does not impose constraints on the structure of surrogate models or require explicit fidelity error characterization. Instead, it constructs an estimator that combines information from multiple fidelities in a computationally efficient manner. MFMC requires an \textit{offline phase}, which involves parameter estimation and surrogate model construction. However, parameter estimation for MFMC is seldom studied and the number of pilot samples are not known to ensure reliable parameter estimation.



The Monte Carlo (MC) method is a fundamental tool for uncertainty quantification, but its slow convergence rate, $1/\sqrt{N}$, makes it computationally expensive, particularly for nonlinear PDEs that require high-fidelity numerical approximations. The multilevel Monte Carlo (MLMC) method \cite{Gi:2008,Gi:2015} mitigates this cost by using a structured hierarchy of models (e.g., spatial grids in PDEs) and relying on sample differences across levels to reduce variance. However, MLMC is not easily applicable to general surrogate models. The multifidelity Monte Carlo (MFMC) method \cite{PeGuWi:2018,PeWiGu:2016,PeWiGu:2018}, in contrast, allows arbitrary surrogate models as long as they are correlated with the high-fidelity model. This makes it applicable to a broader range of problems where hierarchical discretizations are unavailable or difficult to construct. MFMC requires an offline phase for parameter estimation and surrogate model selection. If the offline cost is too high, it may offset the efficiency gains of MFMC, particularly if the number of required high-fidelity samples in the online phase is small. 

Estimating correlation coefficients requires pilot samples, and if the pilot sample size is too small, the correlation is estimated correlations may be unreliable, leading to suboptimal sample allocation and reduced computational gains. Moerover, MFMC’s performance depends on empirical correlation estimates, which lack the rigorous error bounds



While MFMC enhances computational efficiency, its performance hinges on accurate parameter estimation in an \textit{offline phase}, a process that remains underexplored. In particular, the required number of pilot samples for reliable parameter estimation is not well established, posing a critical challenge in balancing offline and online computational costs. Addressing this issue is essential for optimizing MFMC’s practical utility in uncertainty quantification.


The Monte Carlo (MC) method, a classical and widely used approach in uncertainty quantification, relies on repeated executions of deterministic solvers to generate ensembles of realizations for stochastic inputs. Despite its versatility, its practicality is often limited by its slow asymptotic convergence rate of $1/\sqrt{N}$, which often requires a substantial number of sample realizations, $N$, to achieve reliable accuracy. For problems involving non-linear partial differential equations (PDEs), this slow convergence translates into a significant computational burden, as each realization typically demands a high-fidelity numerical approximation, such as those obtained via finite element method, which are computationally expensive due to their fine spatial resolution. To alleviate this challenge, multilevel Monte Carlo (MLMC) is proposed to offset computational cost of MC using low fidelity models that are built on a hierarchy of spatial discretization. However, this method cannot be combined with other arbitrary surrogate models in a easy way as A more detailed interpolation error is required. To overcome this issue and further improve the efficiency, multi-fidelity Monte Carlo (MFMC) method \cite{PeGuWi:2018,PeWiGu:2016} was proposed. It uses the control variate approach to exploit correlations between a computationally expensive high-fidelity model and a series of arbitrary low-fidelity models without considering ugly interpolation error that may associate with the MLMC, yielding an estimator that is accurate enough. Nevertheless, the MFMC method is not without challenges. One notable limitation lies in its reliance on sufficiently large sample sizes to accurately estimate critical statistical parameters, such as variances and correlation coefficients, between high- and low-fidelity models. These estimates are obtained during the \textit{offline computations}, a preparatcory process involving tasks such as parameter estimation and the construction of surrogate models. Once the surrogates are built and parameters are generated in the offline phase, they will then be used in the \textit{online computations}, where the MFMC estimator is assembled and used to perform uncertainty quantification. However, achieving accurate parameter approximations in the offline phase can require substantial computational effort, which, in turn, may offset some of the efficiency gains in the online phase. Despite these challenges, the MFMC method remains an attractive approach due to its potential to accelerate the sampling process. The trade-offs between offline and online cost emphasize the importance of evaluating its applicability on a case-by-case basis to fully realize its potential benefits. \JLcolor{In this study, we extend the analysis of the MFMC method \cite{PeWiGu:2016} by explicitly deriving the required sample size and computational cost as functions of the prescribed accuracy requirements, and derive the pilot sample size for parameter estimation.} Our primary objective is to demonstrate that the MFMC method can achieve significant acceleration in the sampling process while maintaining statistical fidelity. As such, we show that MFMC provides a practical and robust framework for addressing the complex challenges of uncertainty quantification, particularly in the context of plasma equilibrium modeling.




In addition to its computational efficiency, the MFMC method offers notable advantages over surrogate-based MLMC methods, such as those discussed in \cite{ElLiSa:2025, Li:2024}, which rely heavily on the characterization of interpolation errors. Such reliance can be a limiting factor, particularly in scenarios where interpolation errors decay slowly or require complicated error analysis. The MFMC approach circumvents this challenge by accommodating diverse surrogate models without taking into account the explicit treatment of interpolation errors, offering greater flexibility in its application. This adaptability extends the utility of MFMC to a broader range of modeling scenarios, making it particularly valuable in contexts where achieving a balance between computational efficiency and solution accuracy is critical.





low-fidelity models have been proposed as computationally efficient alternatives to high-fidelity simulations.  These models aim to approximate the underlying system with reduced computational cost while maintaining an acceptable level of accuracy. 




For example, \cite{ElLiSa:2022} demonstrates how low-fidelity models constructed using stochastic collocation can effectively accelerate Monte Carlo sampling by exploiting simplified representations of the system. Similarly, \cite{ElLiSa:2023} investigates hierarchical coarse spatial grids to develop low-fidelity surrogate models for multilevel Monte Carlo (MLMC) frameworks \cite{BaScZo:2011,Gi:2008}. Building on these ideas, studies such as \cite{ElLiSa:2025, Li:2024} combine stochastic collocation techniques with multilevel approaches, constructing low-fidelity models on coarse grids for MLMC sampling, further reducing computational expenses. While these methods achieve notable reductions in computational cost, they introduce the risk of compromising accuracy due to the inherent simplifications in the surrogate models. The trade-off between computational efficiency and solution accuracy is, therefore, a critical issue that warrants careful examination to ensure the reliability of results. 




The pursuit of controlled nuclear fusion as a clean and virtually limitless energy source has spurred extensive research into the physics of magnetic confinement in fusion reactors. At the core of this effort lies the Grad–Shafranov free-boundary problem, which governs the equilibrium state of plasma in axially symmetric geometries, such as those found in Tokamaks. The governing equation encapsulates the intricate interplay between magnetic fields and plasma pressure, which determines critical confinement and stability properties essential for efficient plasma performance. However, the predictive accuracy of these models is significantly challenged by uncertainties in the parameters arising from measurement limitations, model assumptions, and operational variability. Addressing these uncertainties effectively requires advanced computational frameworks capable of robust statistical analysis, enabling accurate predictions of the plasma equilibrium response under diverse scenarios and ensuring reliable assessments of reactor designs and operations.

This study focuses on estimating the expectation of the solution operator associated with plasma equilibrium with uncertainties in the parameters. 






 



\JLcolor{The discussion of MLMC is largely based on..., we will not introduce in this paper.}
 
The paper is organized as follows. In Section \ref{sec:Grad-Shafranov}, we introduce the Grad-Shafranov free boundary problem under uncertainty. Section \ref{sec:SC} provides an overview of the sparse grid stochastic collocation technique, which forms the basis to construct low-fidelity models used in the multi-fidelity Monte Carlo framework. Sections \ref{sec:MC} and \ref{sec:MFMC} discuss the Monte Carlo Finite Element method and its multi-fidelity variant. Finally, Section \ref{sec:Num-Exp} presents numerical experiments that access both efficiency and accuracy of these methods.



% Finally, the paper concludes with Section \ref{sec:Conclusion}, summarizing the key findings and contributions. 
% An appendix is included, containing technical mathematical details and proofs relevant to the problem and methods discussed.