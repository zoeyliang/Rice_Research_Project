%!TEX root = ../main.tex
% ====================================================
\section{Multi-fidelity Monte Carlo}\label{sec:MFMC}
% ====================================================
This section reviews the core principles of the multi-fidelity Monte Carlo (MFMC) framework, following the formulation introduced in \cite{PeWiGu:2016}. MFMC combines a high-fidelity (HF) model $u_{1}$ with a sequence of low-fidelity (LF) models $u_{k}:\Omega \rightarrow U$ for $k=2,\ldots,K$. The HF model provides accurate but computationally expensive evaluations, while the LF models offer cheaper, less accurate approximations. By optimally allocating computational resources across fidelity levels, MFMC reduces estimator variance and computational cost while preserving accuracy and robustness.

For brevity, we use $u_k$ to denote the random variable $u_k(\boldsymbol{\omega})$ defined on the probability space $(\Omega,\mathcal{F},\mathbb{P})$. For each pair of $u_{k}$ and $u_{j}$, the variance and Pearson correlation coefficient are defined as
%
\begin{equation*}
    \sigma_k^2 = \mathbb{V}\!\left[u_k\right],\qquad 
    \rho_{k,j} = \frac{\text{Cov}\!\left[u_k,u_j\right]}{\sigma_k\sigma_j}, 
    \quad k,j=1,\dots,K,
\end{equation*}
%
where the covariance $\text{Cov}[u_k,u_j] := \mathbb{E}[\langle u_k - \mathbb{E}[u_k], u_j - \mathbb{E}[u_j]\rangle_U]$ and $\rho_{k,k}=1$ by definition.


The MFMC estimator $A^{\text{MF}}$ augments the HF Monte Carlo (MC) estimate with control-variate corrections from the LF models:
%
\begin{equation}\label{eq:MFMC_estimator}
    A^{\text{MF}} := A^{\text{MC}}_{1,N_1} + \sum_{k=2}^K \alpha_k\left(\overline{A}_{k,N_k} - \overline{A}_{k,N_{k-1}}\right),
\end{equation}
%
where $A^{\text{MC}}_{1,N_1}$ is the standard MC estimator using $N_1$ HF samples, $\alpha_k \in \mathbb{R}$ are control variate weights, and $\overline{A}_{k,N_k}$ denotes the sample average of model $u_{k}$ over $N_k$ samples. The construction of the estimator requires the $\overline{A}_{k,N_{k}}$ reuses all $N_{k-1}$ samples from $\overline{A}_{k,N_{k-1}}$, this indicates the nesting condition $N_{k-1}\le N_k$ for $k=2,\ldots, K$. $\overline{A}_{k,N_{k}}$ reuses all $N_{k-1}$ samples from $\overline{A}_{k,N_{k-1}}$, possibly supplemented by additional $N_{k} - N_{k-1}$ samples. This reuse introduces statistical dependence between $\overline{A}_{k,N_{k-1}}$ and $\overline{A}_{k,N_{k}}$. To eliminate statistical dependence between reused sample sets, we partition the $N_k$ samples into disjoint subsets of sizes $N_{k-1}$ and $N_k-N_{k-1}$, reformulating \eqref{eq:MFMC_estimator} as
%
\begin{equation}\label{eq:MFMC_estimator_independent}
    A^{\text{MF}} = A^{\text{MC}}_{1,N_1} +  \sum_{k=2}^K \alpha_k\!\left(1-\frac{N_{k-1}}{N_k}\right)\left(A^{\text{MC}}_{k,N_k\backslash N_{k-1}}-A^{\text{MC}}_{k,N_{k-1}}\right),
\end{equation}
%
where $A^{\text{MC}}_{k,N_k\backslash N_{k-1}}$ is the MC average over the $N_k-N_{k-1}$ independent samples not included in $A^{\text{MC}}_{k,N_{k-1}}$, and is defined to be zero whenever $N_k=N_{k-1}$. This formulation simplifies the variance analysis by ensuring independence between correction terms.

 We can now express the MFMC estimator in compact form, defining
 %
\begin{equation*}
A^{\text{MF}} = Y_1 + \sum_{k=2}^K \alpha_k Y_k, \qquad 
Y_1 := A^{\text{MC}}_{1,N_1},\quad 
Y_k := \left(1-\frac{N_{k-1}}{N_k}\right)\!\left(A^{\text{MC}}_{k,N_k\backslash N_{k-1}} - A^{\text{MC}}_{k,N_{k-1}}\right), \;\; k=2\ldots, K.
\end{equation*}
%
we observe that each $Y_k$ for $k\ge2$ is the difference of two independent MC estimators of the same model and thus satisfies $\mathbb{E}[Y_k]=0$. Consequently, the MFMC estimator is unbiased, i.e., $\mathbb{E}[A^{\text{MF}}]=\mathbb{E}[u_{1}]$. The variances of $Y_k$ are
%
\begin{equation}\label{eq:Var_Yk}
    \mathbb{V}[Y_1] = \frac{\sigma_1^2}{N_1}, \qquad 
    \mathbb{V}[Y_k] = \left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\sigma_k^2, \;\; k=2\ldots, K.
\end{equation}
%
Although $Y_k$ and $Y_j$ ($2\le k<j\le K$) share overlapping sample sets, they remain uncorrelated (see Lemma~\ref{lemma:Y_k_Y_j} in \cite{LiMh:2025}). Each $Y_k$ ($k\ge2$) is correlated with $Y_1$, and the covariance relation from \cite[Lemma~3.2]{PeWiGu:2016} gives
%
\begin{equation}\label{eq:Cov_Yk}
\text{Cov}[Y_1,Y_k] = - \left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\rho_{1,k}\sigma_1\sigma_k.
\end{equation}
%
Combining \eqref{eq:Var_Yk} and \eqref{eq:Cov_Yk}, the total variance of the MFMC estimator is
%
\begin{equation}\label{eq:MFMC_variance}
    \mathcal{V}^{\text{MF}}
    =\frac{\sigma_1^2}{N_1} 
    + \sum_{k=2}^K \left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\!\left(\alpha_k^2\sigma_k^2 - 2\alpha_k\rho_{1,k}\sigma_1\sigma_k\right).
\end{equation}
%
To determine optimal sample sizes $N_k$ and weights $\alpha_k$ in the MFMC estimator \eqref{eq:MFMC_estimator_independent}, we minimize the estimator variance under a total computational budget
\[
\mathcal{W}^{\text{MF}} = \sum_{k=1}^K C_k N_k,
\]
where $C_k$ is the cost per sample of model $u_k$. Second,  the monotonicity constraints $N_{k-1}\le N_k$ for $k=2,\ldots, K$ ensures consistent sample reuse across fidelity levels. Third, all sample sizes must be non-negative. Following \cite{PeWiGu:2016}, The optimization problem is
%
\begin{equation}\label{eq:Optimization_pb_sample_size}
    \begin{array}{ll}
    \min &\mathcal{V}^{\text{MF}},\\
       \text{subject to} &\displaystyle\sum\limits_{k=1}^K C_kN_k=p,\\[2pt]
       &\displaystyle -N_1\le 0,\quad \displaystyle N_{k-1}-N_k\le 0, \;\; k=2\ldots,K,\\
       &N_1,\ldots, N_K\in \mathbb{R},\\
       &\alpha_2,\ldots,\alpha_K\in \mathbb{R}.
    \end{array}
\end{equation}
%
The real-valued solution to \eqref{eq:Optimization_pb_sample_size} is summarized in Theorem~\ref{thm:Sample_size_est}, which provides optimal control variate weights and sample allocations.

\begin{theorem}[Optimal MFMC real-valued sample allocation]\label{thm:Sample_size_est}
Consider $K$ models $\{u_{k}\}_{k=1}^K$ with standard deviations $\sigma_k$, correlation coefficients $\rho_{1,k}$ with the HF model $u_1$, and per-sample costs $C_k$. Define $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$. Assume the following conditions hold
%
\begin{alignat*}{3}
&(i)\;\textit{Monotone correlations:} &\quad& |\rho_{1,1}| > \cdots > |\rho_{1,K}|,\\
&(ii)\;\textit{Cost-correlation ratio:} &\quad& \frac{\Delta_{k}}{C_k} > \frac{\Delta_{k-1}}{C_{k-1}}, \quad k=2,\ldots,K.
\end{alignat*}
%
Then the optimal control weights and sample sizes to \eqref{eq:Optimization_pb_sample_size} are
%
\begin{equation}\label{eq:MFMC_RealValued_Sample_Size}
    \alpha_k^* = \frac{\rho_{1,k}\sigma_1}{\sigma_k}, \qquad
    N_k^* = \sqrt{\frac{\Delta_k}{C_k}}\,
    \frac{p}{\sum_{j=1}^K \sqrt{C_j \Delta_j}}.
\end{equation}
%
% \[
% r_k^* = \sqrt{\frac{C_1\Delta_k}{C_k\Delta_1}},\quad N_1^* = \frac{p}{\sum_{k=1}^K C_k r^*_k}, \quad N_k^*=N_1^*r_k^*.
% \] 
% %
% \JLcolor{alternatively, in my way to represent it without mentioning the vector $\boldsymbol{r}^*$, we have}
%
The resulting optimal variance of MFMC estimator is
\begin{equation}\label{eq:MFMC_variance_optimal}
\mathcal{V}^{\text{MF}}
= \sigma_1^2\sum_{k=1}^K \frac{\Delta_k}{N_k^*}=\frac{\sigma_1^2}{p}\!\left(\sum_{k=1}^K \sqrt{C_k \Delta_k}\right)^{\!2}.
\end{equation}
\end{theorem}

To study the variance behavior, we introduce the {\it normalized variance functional}, defined in terms of the sample allocation vector $N_k$ as
\[
f(N_k) =\sum_{k=1}^K \frac{\Delta_k}{N_k}.
\]
The corresponding value for the optimal real-valued allocation follows from \eqref{eq:MFMC_variance_optimal} is
%
\[
f(N_k^*) = \frac{1}{p}\left(\sum_{k=1}^K\sqrt{C_k\Delta_k}\right)^2.
\]
%
Furthermore, the sensitivities of the variance and cost with respect to the sample sizes are
\[
\frac{\partial \mathcal{V}^{\text{MF}}(N_k)}{\partial N_k} = -\sigma_1^2\frac{\Delta_k}{N_k^2},
\qquad 
\frac{\partial \mathcal{W}^{\text{MF}}(N_k)}{\partial N_k} = C_k.
\]
These relations indicate the fundamental trade-off between variance and cost: increasing the sample size $N_k$ reduces the estimator variance but increases the total computational cost.




In practice, real-valued sample size $N_k^*$ must be rounded to integers. According to \cite{PeWiGu:2016}, a standard choice is to apply the floor function to $N_k^*$ to obtain $\lfloor N_k^*\rfloor$ as the integer-valued sample size, which guarantees feasibility with respect to the budget constraint in \eqref{eq:Optimization_pb_sample_size}. We use $N_k^*$ as the real-valued solution, and $\lfloor N_k^* \rfloor$ as the floored integer-valued solution throughout the paper. Using this convention, the actual $f$ and total cost are
\[
f\left(\left\lfloor N_k^* \right\rfloor\right) = \sum_{k=1}^K\frac{\Delta_{k}}{\left\lfloor N_k^* \right\rfloor}, \qquad \mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right) = \sum_{k=1}^K C_k\left\lfloor N_k^* \right\rfloor.
\]
The floor operation introduces a bounded overhead due to the integer constraint 
$N_k^*-1 < \lfloor N_k^*\rfloor \le N_k^*$, yielding
%
\begin{align*}
    f\left(\left\lfloor N_k^* \right\rfloor\right)&\in \left[\sum_{k=1}^K\frac{\Delta_{k}}{N_k^*},\; \sum_{k=1}^K\frac{\Delta_{k}}{N_k^*-1}\right) = \left[\frac{1}{p}\left(\sum_{k=1}^K \sqrt{C_k\Delta_k}\right)^2, \sum_{k=1}^K\frac{\Delta_{k}}{\sqrt{\frac{\Delta_k}{C_k}}\frac{p}{\sum_{j=1}^K \sqrt{C_j\Delta_j}}-1}\right)\\
    &=\left[\frac{1}{p}\left(\sum_{k=1}^K \sqrt{C_k\Delta_k}\right)^2, \sum_{k=1}^K \sqrt{C_k\Delta_k}\sum_{k=1}^K\frac{\sqrt{C_k\Delta_{k}}}{p-\sqrt{\frac{C_k}{\Delta_k}}\sum_{j=1}^K \sqrt{C_j\Delta_j}}\right)\\
    % &=\sum_{k=1}^K \sqrt{C_k\Delta_k}\left[\frac{\sum_{k=1}^K \sqrt{C_k\Delta_k}}{p},\sum_{k=1}^K\frac{\sqrt{C_k\Delta_{k}}}{p-\sqrt{\frac{C_k}{\Delta_k}}\sum_{j=1}^K \sqrt{C_j\Delta_j}}\right)\\
    \mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right) &\in \left(\sum_{k=1}^KC_kN_k^*-\sum_{k=1}^K C_k, \sum_{k=1}^KC_kN_k^*\right]=\left( p-\sum_{k=1}^K C_k,p\right].
\end{align*}
%
% %
% \begin{equation}\label{eq:sampling_cost_bound}
% \mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right) \in \left(\sum_{k=1}^KC_kN_k^*-\sum_{k=1}^K C_k, \sum_{k=1}^KC_kN_k^*\right]=\left( p-\sum_{k=1}^K C_k,p\right].
%     % \sum_{k=1}^K C_k N_k^* - \sum_{k=1}^K C_k < \sum_{k=1}^K C_k \left\lfloor N_k^*\right\rfloor \le \sum_{k=1}^K C_k N_k^*,
% \end{equation}
% %
The additive term $\sum_{k=1}^K C_k$ represents the rounding-induced cost slack and remains asymptotically negligible as $p\to\infty$. Consequently, the integer allocation preserves both the efficiency and asymptotic optimality of the real-valued MFMC solution. Moreover, since each fidelity model should have at least one sample, the total cost must satisfy $p\ge \sum_{k=1}^K C_k$ 

However, in the pre-asymptotic regime—where the total budget $p$ is moderate—the rounding slack $\big(p - \mathcal{W}^{\text{MF}}(\lfloor N_k^* \rfloor)\big)$ may cause nontrivial under-utilization of the available budget. A natural question then arises:  
\textit{Can we construct an integer-valued sample size allocation that minimizes this slack, thereby making the realized cost as close as possible to the prescribed budget $p$?}











% particularly in regimes where some $N_k^*$ fall below one. 








