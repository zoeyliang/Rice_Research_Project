%!TEX root = ../main.tex
% ====================================================
\section{Multi-fidelity Monte Carlo}\label{sec:MFMC}
% ====================================================
This section reviews the multi-fidelity Monte Carlo (MFMC) method, following the foundational formulation in \cite{PeWiGu:2016}. The MFMC framework uses an ensemble of models with varying computational cost and accuracy to construct a variance-reduced estimator for high-fidelity expectation. Let $u_1:\Omega \to U$ denote the high-fidelity (HF) model that provides accurate but expensive evaluations, and let $\{u_k\}_{k=2}^K$ denote low-fidelity (LF) models that offer cheaper approximations. The central goal of MFMC is to allocate a fixed computational budget across these models to minimize estimator variance while maintaining unbiasedness.

We introduce some key statistical quantities that describe the model. We represent the random output of model $u_k$ on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ by $u_k(\boldsymbol{\omega})$, abbreviated as $u_k$. For each pair of models $u_k,u_j$, define the variance and correlation coefficient
%
\begin{equation*}
    \sigma_k^2 = \mathbb{V}\!\left[u_k\right],\qquad 
    \rho_{k,j} = \frac{\text{Cov}\!\left[u_k,u_j\right]}{\sigma_k\sigma_j}, 
    \quad k,j=1,\dots,K,
\end{equation*}
%
where the covariance is defined as $\text{Cov}[u_k,u_j] := \mathbb{E}[\langle u_k - \mathbb{E}[u_k], u_j - \mathbb{E}[u_j]\rangle_U]$ and $\rho_{k,k}=1$. The pairwise correlations between fidelity levels quantify the statistical dependence that drives variance reduction through effective control variates.

The MFMC estimator architecture uses a nested sampling strategy that reuses computational evaluations across fidelity levels. Let $A_{1,N_1}^{\text{MC}}$ denote the standard Monte Carlo estimator of $\mathbb{E}[u_1]$ based on $N_1$ HF samples. The MFMC estimator augments this with corrections from lower fidelities via control variates
%
\begin{equation}\label{eq:MFMC_estimator}
A^{\text{MF}} := A^{\text{MC}}_{1,N_1} + \sum_{k=2}^K \alpha_k\left(\overline{A}_{k,N_k} - \overline{A}_{k,N_{k-1}}\right),
\end{equation}
%
where $\alpha_k \in \mathbb{R}$ are control variate weights and $\overline{A}_{k,N}$ denotes the sample average of $N$ evaluations of model $u_k$. A critical aspect of this construction is the nested sampling structure: the estimator $\overline{A}_{k,N_{k}}$ reuses all $N_{k-1}$ samples from $\overline{A}_{k,N_{k-1}}$, possibly supplemented by additional $N_{k} - N_{k-1}$ samples. The reuse of LF evaluations across levels enhances efficiency but induces sample statistical dependencies that complicate variance analysis.



To facilitate analysis, we reformulate the estimator so that its constituent terms are statistically independent. Partitioning the $N_k$ LF samples into disjoint sets of sizes $N_{k-1}$ and $N_k-N_{k-1}$ yields the equivalent independent form
%
\begin{equation}\label{eq:MFMC_estimator_independent}
    A^{\text{MF}} = A^{\text{MC}}_{1,N_1} +  \sum_{k=2}^K \alpha_k\!\left(1-\frac{N_{k-1}}{N_k}\right)\left(A^{\text{MC}}_{k,N_k\backslash N_{k-1}}-A^{\text{MC}}_{k,N_{k-1}}\right),
\end{equation}
%
where $A_{k,N_k\backslash N_{k-1}}^{\text{MC}}$ is the MC average over the $N_k-N_{k-1}$ new samples (defined to be zero when $N_k=N_{k-1}$).


The statistical properties of the MFMC estimator emerge clearly from its component-wise decomposition. Define
%
\begin{equation}\label{eq:MFMC_Yk}
Y_1 := A^{\text{MC}}_{1,N_1},\quad 
Y_k := \left(1-\frac{N_{k-1}}{N_k}\right)\!\left(A^{\text{MC}}_{k,N_k\backslash N_{k-1}} - A^{\text{MC}}_{k,N_{k-1}}\right), \;\; k=2\ldots, K,
\end{equation}
%
then the MFMC estimator can be expressed into a compact form $A^{\text{MF}} = Y_1 + \sum_{k=2}^K \alpha_k Y_k$. Since each $Y_k$ for $k\ge2$ represents a difference of two independent estimators for the same $\mathbb{E}[u_k]$, we immediately obtain $\mathbb{E}[Y_k]=0$ and the MFMC estimator is unbiased: $\mathbb{E}[A^{\text{MF}}]=\mathbb{E}[u_1]$. The variances of the components are
%
\begin{equation}\label{eq:Var_Yk}
    \mathbb{V}[Y_1] = \frac{\sigma_1^2}{N_1}, \qquad 
    \mathbb{V}[Y_k] = \left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\sigma_k^2, \;\; k=2\ldots, K.
\end{equation}
%
A key statistical insight, formalized in Lemma~\ref{lemma:Y_k_Y_j}, establishes that the correction terms are mutually uncorrelated despite sample reuse.
%
\begin{lemma}\label{lemma:Y_k_Y_j}
For $2\le k<j\le K$, 
% the correction terms $Y_k$ and $Y_j$ defined in \eqref{eq:MFMC_Yk} are uncorrelated, i.e., 
$\operatorname{Cov} [Y_k,Y_j ]=0$.
\end{lemma}
%
The proof is provided in the Appendix.

Each correction $Y_k$($k\ge2$) is correlated with $Y_1$, with covariance
\begin{equation}\label{eq:Cov_Yk}
\operatorname{Cov}[Y_1,Y_k] = -\!\left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\rho_{1,k}\sigma_1\sigma_k,
\end{equation}
as shown in \cite[Lemma~3.2]{PeWiGu:2016}. Combining \eqref{eq:Var_Yk} and \eqref{eq:Cov_Yk} gives
%
\begin{equation}\label{eq:MFMC_variance}
    \mathcal{V}^{\text{MF}}
    =\frac{\sigma_1^2}{N_1} 
    + \sum_{k=2}^K \left(\frac{1}{N_{k-1}} - \frac{1}{N_k}\right)\!\left(\alpha_k^2\sigma_k^2 - 2\alpha_k\rho_{1,k}\sigma_1\sigma_k\right).
\end{equation}
%

In order to determine optimal sample sizes $N_k$ and weights $\alpha_k$ in the MFMC estimator \eqref{eq:MFMC_estimator_independent}, an optimization problem is formulated \cite{PeWiGu:2016} by minimizing the estimator variance \eqref{eq:MFMC_variance} subject to a fixed budget $p$. Let $C_k$ denote the per-sample cost of model $u_k$, the total computational cost is 
%
\[
\mathcal{W}^{\text{MF}} = \sum_{k=1}^K C_k N_k,
\]
%
and the constrained optimization problem becomes
%
\begin{equation}\label{eq:Optimization_pb_sample_size}
    \begin{array}{ll}
    \min &\mathcal{V}^{\text{MF}}\left(\alpha_k,N_k\right),\\
       \text{subject to} &\displaystyle\sum\limits_{k=1}^K C_kN_k=p,\\[2pt]
       &\displaystyle N_1\ge 0,\quad \displaystyle N_{k-1}\le N_k, \;\; k=2\ldots,K,\\
       &N_1,\ldots, N_K\in \mathbb{R},\\
       &\alpha_2,\ldots,\alpha_K\in \mathbb{R}.
    \end{array}
\end{equation}
%
Note that for each level $k\ge 2$, $\alpha_k$ enters only through a quadratic expression independent of $N_k$ in the variance term. This separable structure allows a fundamental simplification of the variance functional, which allows hierarchical minimization
%
\begin{equation*}
    \min_{\alpha_k,\, N_k} \mathcal{V}^{\text{MF}}\left(\alpha_k, N_k\right)
    = \min_{N_k}\Big(\min_{\alpha_k} \mathcal{V}^{\text{MF}}(\alpha_k, N_k)\Big).
\end{equation*}
%
The hierarchical minimization admits a closed-form solution for optimal weights by solving the inner optimization $\partial \mathcal{V}^{\text{MF}}/\partial \alpha_k = 0$, yielding 
%
\begin{equation}\label{eq:MFMC_weights}
    \alpha_k^* = \frac{\rho_{1,k}\sigma_1}{\sigma_k}.
\end{equation}
%
Substituting $\alpha_k^*$ into \eqref{eq:MFMC_variance} simplifies the variance to 
%
\begin{equation*}
    \mathcal{V}^{\text{MF}}\left(\alpha_k^*, N_k\right)
    = \sigma_1^2\sum_{k=1}^K \frac{\Delta_k}{N_k},
\end{equation*}
%
where $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$. This reduces the joint optimization to a continuous resource allocation problem involving only sample allocation
%
\begin{equation}\label{eq:Optimization_pb_sample_size_reduced}
    \begin{array}{ll}
    \min &\displaystyle f(N_k) =\sum_{k=1}^K \frac{\Delta_k}{N_k},\\
       \text{subject to} &\displaystyle\sum\limits_{k=1}^K C_kN_k=p,\\[2pt]
       &\displaystyle -N_1\le 0,\quad \displaystyle N_{k-1}-N_k\le 0, \;\; k=2\ldots,K,\\
       &N_1,\ldots, N_K\in \mathbb{R},
    \end{array}
\end{equation}
%
where $f(N_k)$ is the {\it normalized variance functional}. Under suitable monotonicity and ordering assumptions, this problem admits an analytic solution that characterizes the optimal allocation of resources across fidelity levels.


%
\begin{theorem}[Optimal MFMC real-valued sample allocation]\label{thm:Sample_size_est}
Consider $K$ models $\{u_{k}\}_{k=1}^K$ with standard deviations $\sigma_k$, correlation coefficients $\rho_{1,k}$ of LF model $u_k$ with the HF model $u_1$, and per-sample costs $C_k$. Define $\Delta_k = \rho_{1,k}^2 - \rho_{1,k+1}^2$ for $k = 1, \dots, K$ with $\rho_{1,K+1}=0$. Assume the following conditions hold
%
\begin{alignat*}{3}
&(i)\;\textit{Monotone correlations:} &\quad& |\rho_{1,1}| > \cdots > |\rho_{1,K}|,\\
&(ii)\;\textit{Cost-correlation ratio:} &\quad& \frac{\Delta_{k}}{C_k} > \frac{\Delta_{k-1}}{C_{k-1}}, \quad k=2,\ldots,K.
\end{alignat*}
%
Then the optimal control weights and sample sizes for \eqref{eq:Optimization_pb_sample_size} are
%
\begin{equation}\label{eq:MFMC_RealValued_Sample_Size}
    \alpha_k^* = \frac{\rho_{1,k}\sigma_1}{\sigma_k}, \qquad
    N_k^* = \sqrt{\frac{\Delta_k}{C_k}}\,
    \frac{p}{\sum_{j=1}^K \sqrt{C_j \Delta_j}}.
\end{equation}
%
% \[
% r_k^* = \sqrt{\frac{C_1\Delta_k}{C_k\Delta_1}},\quad N_1^* = \frac{p}{\sum_{k=1}^K C_k r^*_k}, \quad N_k^*=N_1^*r_k^*.
% \] 
% %
% \JLcolor{alternatively, in my way to represent it without mentioning the vector $\boldsymbol{r}^*$, we have}
%
The resulting minimal variance of the MFMC estimator is
\begin{equation}\label{eq:MFMC_variance_optimal}
\mathcal{V}^{\text{MF}}
= \sigma_1^2\sum_{k=1}^K \frac{\Delta_k}{N_k^*}=\frac{\sigma_1^2}{p}\!\left(\sum_{k=1}^K \sqrt{C_k \Delta_k}\right)^{\!2}.
\end{equation}
\end{theorem}
%


Differentiating the normalized variance and cost with respect to the sample sizes gives
%
\[
\frac{\partial f}{\partial N_k} = -\frac{\Delta_k}{N_k^2},
\qquad 
\frac{\partial \mathcal{W}^{\text{MF}}}{\partial N_k} = C_k.
\]
%
These relations quantify the variance–cost trade-off: increasing samples at any level reduces variance at the expense of computational resources. At the continuous optimum \eqref{eq:MFMC_RealValued_Sample_Size}, the marginal variance reduction per unit cost $\Delta_k/(C_k N_k^2)$ is identical across all active models, establishing a balanced resource allocation that characterizes the optimal allocation.

While Theorem~\ref{thm:Sample_size_est} provides real-valued optimal allocations $N_k^*$, practical implementation requires integer sample sizes. The standard approach \cite{PeWiGu:2016} applies the floor function $\lfloor N_k^* \rfloor$ to ensure budget feasibility. The realized variance and cost are
%
\[
f\left(\left\lfloor N_k^* \right\rfloor\right) = \sum_{k=1}^K\frac{\Delta_{k}}{\left\lfloor N_k^* \right\rfloor}, \qquad \mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right) = \sum_{k=1}^K C_k\left\lfloor N_k^* \right\rfloor.
\]
%
Since $N_k^*-1 < \lfloor N_k^*\rfloor \le N_k^*$, the floor operation induces bounded sub-optimality, producing the bounds
%
\begin{equation}\label{eq:bounds_for_floor}
\begin{aligned}
    % f\left(\left\lfloor N_k^* \right\rfloor\right)&\in \left[\sum_{k=1}^K\frac{\Delta_{k}}{N_k^*},\; \sum_{k=1}^K\frac{\Delta_{k}}{N_k^*-1}\right) = \left[\frac{1}{p}\left(\sum_{k=1}^K \sqrt{C_k\Delta_k}\right)^2, \sum_{k=1}^K\frac{\Delta_{k}}{\frac{p}{\sum_{j=1}^K \sqrt{C_j\Delta_j}}\sqrt{\frac{\Delta_k}{C_k}}-1}\right)\\
    % &=\left[\frac{1}{p}\left(\sum_{k=1}^K \sqrt{C_k\Delta_k}\right)^2, \sum_{k=1}^K \sqrt{C_k\Delta_k}\sum_{k=1}^K\frac{\sqrt{C_k\Delta_{k}}}{p-\sqrt{\frac{C_k}{\Delta_k}}\sum_{j=1}^K \sqrt{C_j\Delta_j}}\right)\\
    % &=\sum_{k=1}^K \sqrt{C_k\Delta_k}\left[\frac{\sum_{k=1}^K \sqrt{C_k\Delta_k}}{p},\sum_{k=1}^K\frac{\sqrt{C_k\Delta_{k}}}{p-\sqrt{\frac{C_k}{\Delta_k}}\sum_{j=1}^K \sqrt{C_j\Delta_j}}\right)\\
    % \mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right) &\in \left(\sum_{k=1}^KC_kN_k^*-\sum_{k=1}^K C_k, \sum_{k=1}^KC_kN_k^*\right]=\left( p-\sum_{k=1}^K C_k,p\right].
    f\left(\left\lfloor N_k^* \right\rfloor\right) \in \left[\frac{1}{p}\left(\sum_{k=1}^K \sqrt{C_k\Delta_k}\right)^2, \sum_{k=1}^K\frac{\Delta_{k}}{N_k^*-1}\right), \qquad
\mathcal{W}^{\text{MF}}\left(\left\lfloor N_k^* \right\rfloor\right)\in \left( p-\sum_{k=1}^K C_k, p\right].
\end{aligned}
\end{equation}
%
The term $\sum_{k=1}^K C_k$ represents the rounding-induced slack in the budget, which becomes negligible asymptotically as $p \to \infty$. However, in the pre-asymptotic regime -- where the total budget $p$ is moderate -- this  slack can lead to significant under-utilization of the computational resources. This observation naturally motivates \textit{the development of  alternative integer-valued allocation strategies that reduce slack and achieve tighter budget utilization.}





% This quantity is the marginal variance reduction rate — how much the total variance decreases when you spend more samples at level by taking one more sample cost $C_k$. So the marginal variance reduction per unit cost
% \[
% \frac{-\frac{\partial f}{\partial N_k}}{C_k} = \frac{\Delta_k}{C_kN_k^2}
% \]
% It quantifies that How much variance reduction we get per unit cost at level $k$.
% At the optimum, the system reaches equilibrium where every active model yields the same return per cost unit,
% \[
% \frac{\Delta_k}{C_kN_k^2} = \text{Constant}=\frac{1}{p^2}\left(\sum_{k=1}^K \sqrt{C_k \Delta_k}\right)^{\!2}, \quad \text{for all active}\;\; k.
% \]
















