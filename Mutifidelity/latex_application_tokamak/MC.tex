%!TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================
\section{Monte Carlo Method}\label{sec:MC}
% ====================================================

A standard approach to approximate the expectation in \eqref{eq:expectation_of_u} is the MC method; 
see, e.g.,  \cite{MBGiles_2015a,MDGunzburger_CGWebster_GZhang_2014a}.
Because MLMC methods \cite{MBGiles_2015a,SHeinrich_2001a} and 
(MFMC) methods  \cite{BPeherstorfer_KWillcox_MDGunzburger_2016a, BPeherstorfer_KWillcox_MDGunzburger_2018a}  build on MC, we provide a brief review of MC.


Because $u$ cannot be evaluated, but only an approximation $u_h \in   L_{\mathbb{P}}^2(W, \cU)$ can be 
computed, we first estimate $\mathbb{E}[u_h ]$, 
The MC estimator $A^{\text{MC}}_{N}$ of $\mathbb{E}[u_h ]$ 
is the sample mean over $N$ independent and identically distributed (i.i.d.) realizations 
\begin{equation}\label{eq:MC_estimator}
    A^{\text{MC}}_{N} := \frac{1}{N}\sum_{i=1}^{N} u_h \big(\omega^{(i)} \big).
\end{equation}
%
This estimator is unbiased,  $\mathbb{E}[A^{\text{MC}}_{N}] = \mathbb{E}[u_h ]$, 
and has variance $\mathbb{V}[A^{\text{MC}}_{N}] = N^{-1} \mathbb{V}[u_h ]$, 
where the variance is defined as in \eqref{eq:variance_of_u}.
By the central limit theorem, the MC estimator $A^{\text{MC}}_{N}$ converges in distribution to $\mathbb{E}[u_h]$ as $N$ approaches infinity. 

To quantify the error between $\mathbb{E}[u]$, the quantify we are really interested in, and the estimate $A^{\text{MC}}_{N}$ we can compute,
we consider the  {\it normalized mean squared error (nMSE)}, defined as
 \[
             \mathcal{E}_{A^{\text{MC}}_{N}}^2:= \mathbb E\left[ \big\| \mathbb{E}[u]-A^{\text{MC}}_{N}  \big\| _{U}^2\right]  
                                                                           \big/ \, \big\| \mathbb{E}[u]  \big\| _{U}^2.
\] 
The nMSE decomposes into two contributions: a {\it bias error} from  discretization, and a {\it statistical error} due to finite sampling:
%
\[
\mathcal{E}_{A^{\text{MC}}_{N}}^2 
= \frac{ \big\| \mathbb{E}[u]-\mathbb{E}[u_h ]  \big\| _{U}^2
               +\mathbb E\left[ \big\|  \mathbb{E}[u_h ] -A^{\text{MC}}_{N}  \big\| _{U}^2\right]}{ \big\| \mathbb{E}[u]  \big\| _{U}^2} 
= \frac{ \big\| \mathbb{E}[u]-\mathbb{E}[u_h ]  \big\| _{U}^2}{ \big\| \mathbb{E}[u]  \big\| _{U}^2}
    +\frac{\mathbb{V}\left[u_h \right]} {N \, \big\| \mathbb{E}[u]  \big\| _{U}^2}
=\mathcal{E}_{\text{Bias}}^2 + \mathcal{E}_{\text{Stat}}^2.
\]


The bias error is determined by the discretization and the statistical error is determined by the sampling.
Given a user-specified threshold $\epsilon^2$  for the nMSE, we introduce a {\it splitting ratio} $\theta \in (0,1)$ 
and require that $\mathcal{E}_{\text{Bias}}^2 \le \theta\epsilon^2$ and 
$\mathcal{E}_{\text{Stat}}^2  \le (1-\theta)\epsilon^2$.

Suppose the sample-wise discretization error satisfies
\begin{equation*} \label{eq:Assumption_uhA}
       \left\| u\big(\omega^{(i)}\big) - u_h\big(\omega^{(i)}\big)\right\|_U
       \leq c_u h^\alpha.
\end{equation*}
Then we pick a mesh size $h$ such that
\begin{subequations} \label{eq:error-budget}
\begin{equation}
     \mathcal{E}_{\text{Bias}}^2
     =  \big\| \mathbb{E}[u]-\mathbb{E}[u_h ]  \big\| _{U}^2   \big/ \,   \big\| \mathbb{E}[u]  \big\| _{U}^2
     \le  \|u-u_h\|_{L^2(W,\cU)}^2    \big/ \,   \big\| \mathbb{E}[u]  \big\| _{U}^2
     \le c_u^2  h^{2\alpha} \le \theta\epsilon^2.
\end{equation}
and a sample size $N$ such that
\begin{equation} 
        \mathcal{E}_{\text{Stat}}^2 
           = \mathbb{V}( u_h )   \big/ \,  \big( N \, \big\| \mathbb{E}(u)  \big\| _{U}^2 \big)
          \le (1-\theta)\epsilon^2,
\end{equation}
\end{subequations}
To meet these error constraints \eqref{eq:error-budget}, the mesh size  $h$ and sample size $N$ must obey
\begin{equation}  \label{eq:SLSGC_SL_SpatialGridsNo_n_SparseGridsNo}
       h \le \Big( \sqrt{\theta}\epsilon / c_u \Big)^{1/\alpha} \quad \text{and} \quad  
       N \ge   \mathbb{V}( u_h )  \Big/ \Big( \epsilon^2(1-\theta) \, \big\| \mathbb{E}(u)  \big\| _{U}^2 \Big).
\end{equation}
In practice, $N$ is chosen to the smallest integer satisfying \eqref{eq:SLSGC_SL_SpatialGridsNo_n_SparseGridsNo}.
Assuming each evaluation of $u_h$ incurs an average cost of $C$, the total cost to compute $A^{\text{MC}}_{N}$ is
\begin{equation} \label{eq:MC-work}
       \mathcal{W}^\text{MC}  =  \frac{ C\, \mathbb{V}( u_h ) }{  \epsilon^2(1-\theta) \, \big\| \mathbb{E}(u)  \big\| _{U}^2}.
\end{equation}

