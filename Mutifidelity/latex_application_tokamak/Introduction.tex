%!TEX root = main.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ========================================
\section{Introduction}\label{sec:intro}
% ========================================
The Monte Carlo (MC) method is a fundamental tool for uncertainty quantification in computational science and engineering. It estimates statistical properties of quantities influenced by stochastic inputs through repeated evaluations of a deterministic model. Its non-intrusive nature and broad applicability -- requiring no assumptions about the smoothness or structure of the input distributions -- make it widely appealing. However, a key limitation of the MC method is its slow convergence rate of $1/\sqrt{N}$, where $N$ is the number of samples, which leads to high computational costs, particularly when the evaluation of each model is expensive. Such costs are especially pronounced in the context of non-linear partial differential equations (PDEs), which typically require high-fidelity numerical discretizations -- such as fine-mesh finite element methods -- to accurately resolve the solution. Consequently, direct application of standard MC methods to these problems can become computationally prohibitive. To mitigate this burden, surrogate models have been developed as low-fidelity approximations that retain essential features of the high-fidelity model while offering substantial reductions in cost. These models accelerate sampling by approximating the underlying system at coarser resolution or through simplified representations while retaining sufficient accuracy for statistical inference. However, the simplifications inherent in surrogate construction can introduce bias and reduce accuracy, particularly in regions where the surrogate fails to capture important solution features. For instance, \cite{ElLiSa:2022} demonstrates that surrogate models based on stochastic collocation can significantly accelerate MC sampling while maintaining reliable accuracy. An alternative strategy to accelerate Monte Carlo sampling is provided by the multilevel Monte Carlo (MLMC) method \cite{BaScZo:2011,Gi:2008,Gi:2015}, which constructs a hierarchy of spatial discretizations to efficiently estimate statistical quantities. The key idea is to compute most of the variance contribution using inexpensive coarse-grid models, while reserving costly fine-grid evaluations for corrections at the highest resolution. This hierarchical approach significantly reduces the total computational cost compared to standard MC methods. For example, \cite{ElLiSa:2023} investigates the application of MLMC for uncertainty quantification in PDEs, demonstrating its effectiveness in reducing computational burden. In this paper, we address these limitations by adopting the multifidelity Monte Carlo (MFMC) framework \cite{PeGuWi:2018,PeWiGu:2016,PeGuWi:2018}, which generalizes the multilevel paradigm by combining models of varying fidelity through control variates. Unlike MLMC, MFMC does not require a nested hierarchy of discretizations, allowing for greater flexibility in the selection and integration of surrogate models. While MFMC incurs some upfront cost associated with surrogate construction and variance estimation, it offers some computational savings over both standard MC and MLMC, especially in regimes where low-fidelity models are inexpensive yet sufficiently accurate to inform high-fidelity predictions.



The paper is organized as follows. Section~\ref{sec:Grad-Shafranov} introduces the Grad-Shafranov free boundary problem under uncertainty. Section~\ref{sec:SC} reviews the sparse grid stochastic collocation technique, which serves as the foundation for constructing low-fidelity models in the MFMC framework. Sections~\ref{sec:MC} and~\ref{sec:MFMC} present the Monte Carlo finite element method and its multifidelity extension, respectively. As the discussion of MLMC closely follows \cite{ElLiSa:2025}, we do not provide a detailed exposition in this work. Finally, Section~\ref{sec:Num-Exp} reports numerical experiments evaluating the efficiency and accuracy of the proposed methods.

 




% Finally, the paper concludes with Section \ref{sec:Conclusion}, summarizing the key findings and contributions. 
% An appendix is included, containing technical mathematical details and proofs relevant to the problem and methods discussed.


